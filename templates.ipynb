{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openai","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install langchain-openai","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Below Code is for getting the embeddings with the help of OpenAI \nfrom openai import OpenAI\nimport os\nimport openai\n\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"sk-XXXXXXXXXXXXXXXXXXXXXXXX\"))\n\nEMBEDDING_MODEL = 'text-embedding-3-small'\n\n\ndef get_embedding(text_or_tokens, model=EMBEDDING_MODEL):\n    return client.embeddings.create(input=text_or_tokens, \n                                    model=model).data[0].embedding\n\n\n\nget_embedding(\"Hello Python\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Below code is using the Lanchain-openai \n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(api_key=\"...\")\n\nfrom langchain_core.prompts import ChatPromptTemplate\n\n\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are world class technical documentation writer.\"),\n    (\"user\", \"{input}\")\n])\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Embeddings Models Using Langchain\n\nfrom langchain_openai import OpenAIEmbeddings\n\nembeddings_model = OpenAIEmbeddings(api_key=\"...\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings = embeddings_model.embed_documents(\n    [\n        \"Hi there!\",\n        \"Oh, hello!\",\n        \"What's your name?\",\n        \"My friends call me World\",\n        \"Hello World!\"\n    ]\n)\nlen(embeddings), len(embeddings[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedded_query = embeddings_model.embed_query(\"What was the name mentioned in the conversation?\")\nembedded_query[:5]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Vector Stores:\n# the chroma vector database, which runs on your local machine as a library.\npip install langchain-chroma","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport getpass\n\nos.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom langchain_community.document_loaders import TextLoader\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_text_splitters import CharacterTextSplitter\nfrom langchain_chroma import Chroma\n\n# Load the document, split it into chunks, embed each chunk and load it into the vector store.\nraw_documents = TextLoader('../../../state_of_the_union.txt').load()\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\ndocuments = text_splitter.split_documents(raw_documents)\ndb = Chroma.from_documents(documents, OpenAIEmbeddings())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Similarity search\nquery = \"Who is the Current president of India\"\ndocs = db.similarity_search(query)\nprint(docs[0].page_content)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Similarity search by vector\n# It is also possible to do a search for documents similar to a given embedding vector using similarity_search_by_vector which accepts an embedding vector as a parameter instead of a string.\n\nembedding_vector = OpenAIEmbeddings().embed_query(query)\ndocs = db.similarity_search_by_vector(embedding_vector)\nprint(docs[0].page_content)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}